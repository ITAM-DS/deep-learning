{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Problemas de generalización\n",
    "\n",
    "clase 11, 24 de febrero de 2021\n",
    "\n",
    "---\n",
    "Cuando se crea un modelo esperamos que este haya generalizado de manera correcta, sin embargo, es posible que no tenga el rendimiento o propiedades de generalización esperadas. \n",
    "\n",
    "Para producción.\n",
    "\n",
    "Entre los principales problemas de generalización se encuentran los siguientes:\n",
    "\n",
    "* Datos: fijos, no nos hemos preguntado si son suficientes o representativos de la población de dónde vienen.\n",
    "* Ambiente: la interacción de los usuarios que puede llevar a un sesgo en el conjunto de prueba.\n",
    "* Quisiéramos tener buenas capacidades predictivas que no observamos/usamos para entrenar.\n",
    "\n",
    "\n",
    "## 1 Cambio en la distribución de los datos\n",
    "\n",
    "Entrenamiento recibimos atributos y etiquetas para un conjunto de datos $(X^{(i)},y^{(i)})_{\\ i=1,..,n} \\sim \\Pi(x,y)$ y establecemos un modelo $h(x^{(i)}) \\approx y^{(i)}$ que sea capaz de regresar una buena predicción, la cual busca minimizar una función de pérdida $L_{n}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathscr{l}^{(i)}(\\hat{y}(\\theta),y)$.\n",
    "\n",
    "La solución $\\theta^{s} = argmin (L_{n} | \\theta)$.\n",
    "\n",
    "\n",
    "Prueba (Validación) tenemos otro conjunto de datos: $(X_{p}^{(i)},y_{p}^{(i)}) \\sim^{iid} \\Pi(X,y), i = 1,...,m$.\n",
    "\n",
    "Lo que hacemos es evaluar la función de pérdida con este nuevo conjunto de entrenamiento con la solución que encontramos en el entrenamiento. \n",
    "\n",
    "$L_{m}(\\theta^{s}) = \\frac{1}{m} \\sum_{j=1}^{m} \\mathscr{l}^{(j)}\\ (\\hat{y}(\\theta),y)$\n",
    "\n",
    "Esperamos que lo que encontramos en el conjunto de entrenamiento sea cercano al error general, es decir, $L_{m}(\\theta^{s}) \\approx L_{\\Pi}\\ (\\theta^{s}) = \\int \\int  \\mathscr{l}^{(j)}(\\hat{y}\\ (\\theta),y) \\ \\Pi(x,y) \\ \\text{dx}\\text{dy}$.\n",
    "\n",
    "Cuando $(x^{(j)},y^{(j)}) \\sim^{iid} \\tilde{\\Pi}(x,y)$ va a ser erróneo $\\tilde{\\Pi} \\neq \\Pi$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Estrategia de mitigación\n",
    "\n",
    "* Regulación\n",
    "* Dropout\n",
    "\n",
    "### 1.1 Variación en covariables\n",
    "\n",
    "Suponemos que $\\Pi(x,y) = \\Pi(y|x)\\ \\Pi(x)$ y además suponemos que $\\tilde{\\Pi}(x,y) \\neq \\Pi(x,y)$,\n",
    "\n",
    "donde:\n",
    "\n",
    "* $\\tilde{\\Pi}(x,y)$ es la distribución de la población,\n",
    "* $\\Pi(x,y)$ es la distribución que genera los datos de entrenamiento.\n",
    "\n",
    "Esta diferencia en las distribuciones se debe a que $\\tilde{\\Pi}(x,y) = \\tilde{\\Pi}(x)\\ \\Pi(y|x)$, lo que implica que $\\tilde{\\Pi}(x) \\neq \\Pi(x)$. $\\Pi(y|x)$ establece como generan las etiquetas de los objetos.\n",
    "\n",
    "Ejemplos:\n",
    "\n",
    "##### Clasificación de imágenes\n",
    "\n",
    "* Entrenamiento: conjunto de imágenes reales\n",
    "* Prueba: Conjunto de imágenes de caricatura\n",
    "\n",
    "##### Ventas en línea\n",
    "\n",
    "* Entrenar: conjunto de datos de México\n",
    "* Prueba: Pronosticar las ventas en Europa\n",
    "\n",
    "##### Reconocimiento de voz\n",
    "\n",
    "* Entrenamiento: generar texto automatizado entrenado con gente de la CDMX\n",
    "* Prueba: producto será utilizado en MTY\n",
    "\n",
    "$$\\$$\n",
    "\n",
    "En esto contexto estaríamos evaluando una función de pérdida\n",
    "\n",
    "${}^{(1)}$ $\\int \\int \\ \\mathscr{l}(h(x),y) \\ \\Pi(x)\\ \\Pi(y|x) \\ \\text{dxdy} \\neq \\int \\int \\mathscr{l}(h(x),y)\\  \\tilde{\\Pi}(x)\\ \\Pi(y|x) \\ \\text{dxdy}$ ${}^{(2)}$\n",
    "\n",
    "Se puede reescribir de la siguiente manera:\n",
    "\n",
    "${}^{(2)}$ $= \\int \\int \\  \\mathscr{l}(h(x),y) \\  \\frac{\\tilde{\\Pi}(x)}{\\Pi(x)}\\ \\Pi(x)\\ \\Pi(y|x) \\text{dxdy}$\n",
    "\n",
    "Definimos  a $\\alpha(x) = \\frac{\\tilde{\\Pi}(x)}{\\Pi(x)}$\n",
    "\n",
    " Sí $\\alpha(x) =1$, la pérdida en entrenamiento sería igual que la pérdida de validación (prueba).\n",
    "\n",
    " Sí $\\alpha(x) \\neq 1$\n",
    "\n",
    "${}^{(2)} \\Rightarrow $ $(x^{(i)},y^{(i)}) \\sim^{iid} \\Pi(x)\\ \\Pi(y|x)$.\n",
    "\n",
    "${}^{(2)} \\approx \\frac{1}{n} \\sum_{i=1}^{n} \\alpha(x^{(i)})\\ \\mathscr{l}(h(x^{(i)}),y^{(i)})$ (aproximación Monte Carlo).\n",
    "\n",
    "La mejor forma es encontrar la función $h(x^{(i)})$ que minimice la función de pérdida con un nuevo ponderador $\\alpha$.\n",
    "\n",
    "Problema: solo tenemos observaciones  y no conocemos $\\frac{\\tilde{\\Pi}}{\\Pi}$.\n",
    "\n",
    "Solución: Entrenar un clasificador que distinga entre $\\tilde{\\Pi}$ y $\\Pi$.\n",
    "\n",
    "$   \\tilde{y} = \\begin{cases} \n",
    "      1 & \\text{si x es un elemento del conjunto de validación} \\\\\n",
    "      -1 & \\text{si x es un elemento del conjunto de entrenamiento}\n",
    "   \\end{cases}\n",
    " $\n",
    " \n",
    " Con el clasificador binario esperamos que emita probabilidades.\n",
    " \n",
    " $ P(\\tilde{y}=1|x) = \\frac{\\tilde{\\Pi}(x)}{\\tilde{\\Pi}(x)\\ +\\ \\Pi(x)}$.\n",
    " \n",
    " De tal forma que si tenemos un clasificador que emita estas probabilidades, los pesos estarán dados de la siguiente forma:\n",
    " \n",
    " $\\alpha(x) = \\frac{\\tilde{\\Pi}(x)}{\\Pi(x)} = \\frac{P(\\tilde{y}=1|x)}{P(\\tilde{y}=-1|x)}$.\n",
    " \n",
    " Podemos softmax para dos etiquetas = regresión logística, dada por la siguiente ecuación: \n",
    " \n",
    " $ P(\\tilde{y}=1|x) = \\frac{exp(O_{1}(x))}{exp(O_{1}(x)) + exp(O_{2}(x))} = \\frac{1}{exp(-\\tilde{h}(x))}$.\n",
    " \n",
    " Con $\\tilde{h}_{i}(x) = O_{i}(x)-O_{2}(x)$ y $\\tilde{h} = \\hat{h}_{i}$.\n",
    " \n",
    " $\\hat{\\alpha}(x) = exp(\\tilde{h}(x))$.\n",
    " \n",
    " De tal forma que ya tenemos un clasificador que distingue entre datos de entrenamiento y datos de clasificación, podemos ponderar las observaciones. \n",
    " \n",
    " Para posteriormente entrenar el modelo $\\Rightarrow L_{n}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} \\hat{\\alpha}(x^{(i)}) \\ \\mathscr{l}(h(x^{(i)}, \\theta),y^{(i)}) $.\n",
    " \n",
    " Minimizamos para encontrar $\\theta^{*}$ que tenga la mejor relación entre $x$ y $y$, considerando los pesos $\\hat{\\alpha}(x^{(i)})$.\n",
    " \n",
    " Supuesto: $x$ como una muestra de $\\Pi$ también es una muestra aleatoria válida de $\\tilde{\\Pi}$, es decir, no hay una diferencia fundamental entre las distribuciones.\n",
    " \n",
    " Si tenemos una observación $(k \\in {1,...,n})$ tal que $\\Pi(x^{(k)}) > 0$ y $\\tilde{\\Pi}(x^{(k)})=0$ $ \\Rightarrow \\alpha(x^{(k)}) = 0$.\n",
    " \n",
    " $L_{n}(h) \\rightarrow L_{<n}(h) = \\frac{1}{n} \\sum_{i=1}^{m} \\ \\alpha(x^{(i)})\\ \\mathscr{l}(...) \\ m<n $\n",
    " \n",
    " Es decir, hay elementos que no son representativos de esta relación.\n",
    " \n",
    " \n",
    " ### 1.2 Variación en las etiquetas\n",
    " \n",
    " Asumimos que $\\Pi(x,y) = \\Pi(y)\\ \\Pi(x|y)$ y que $\\Pi(y) \\neq \\tilde{\\Pi}(y)$.\n",
    " \n",
    " Asumimos que $\\Pi(x|y)$ se mantiene igual, mismas características.\n",
    " \n",
    " Ejemplo: clasificación con k etiquetas\n",
    " \n",
    " $\\Pi(y) \\rightarrow \\Pi_{y} \\in \\mathbb{R}^{k}$\n",
    " \n",
    " * Diagnóstico médicos\n",
    "     - Entrenamiento: con pocos pacientes\n",
    "     - Validación: periodo de contagio masivo (proporción es mucho mayor que cuando se entrena)\n",
    "     \n",
    "     \n",
    " * Reconocimiento de diálogos\n",
    "     - Entrenamiento: durante campaña electoral\n",
    "     - Validación: fuera de campaña electoral (diferente proporción de palabras)\n",
    "\n",
    "\n",
    "$ \\int \\int \\mathscr{l}(h(x), y) \\ \\tilde{\\Pi}(y) \\ \\Pi(x|y) \\ \\text{dxdy}$\n",
    "\n",
    "$= \\int \\int \\mathscr{l}(h(x), y) \\ \\frac{\\tilde{\\Pi}(y)}{\\Pi(y)} \\ \\Pi(y) \\  \\Pi(x|y) \\ \\text{dxdy}$\n",
    "\n",
    "donde $\\frac{\\tilde{\\Pi}(y)}{\\Pi(y)}$ son los pesos y $\\Pi(y) \\  \\Pi(x|y) $ es la distribución de entrenamiento.\n",
    "\n",
    "Corrección: algoritmo de corrección  espectral.\n",
    "\n",
    "La idea es: \n",
    "\n",
    "$(i)$ Se entrena un clasificador y se obtiene la matriz de confusión en un conjunto ajeno al de entrenamiento.\n",
    "\n",
    "\n",
    "| Entrenamiento | Validación |\n",
    "|---------------|------------|\n",
    "| | |\n",
    "\n",
    "$(ii)$ Utilizamos el clasificador en el conjunto de prueba. Calculamos el $\\%$ de las etiquetas $\\mu \\in \\mathbb{R}^{t}$, $c\\tilde{\\Pi} = \\mu$ y se resuelve el sistema $\\tilde{\\Pi} \\Rightarrow \\alpha_{i} = \\frac{\\tilde{\\Pi}_{i}}{Pi_{i}}$"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
