{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--  RENAME CURRENT FILE TO MATCH LECTURE NUMBER AND A GOOD DESCRIPTOR OF THE CONTENT -->\n",
    "<!--  E.g., \"01_introduccion.Rmd\" -->\n",
    "\n",
    "<!-- >>>>>>> LECTURE NUMBER AND TITLE -->\n",
    "\n",
    "# Clase 3: Métodos Iterativos\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Previamente, se revisó que el problema de sobreajuste se deriva de la diferencia que existe entre la pérdida calculada y la pérdida empírica de los datos\n",
    "$$\n",
    "\\mathcal{L}_n (w) \\neq \\mathcal{L}_{\\Pi} (w)  \\,.\n",
    "$$\n",
    "\n",
    "Donde, en el contexto de regresión podemos escribir la pérdida empírica como promedio de pérdidas individuales:\n",
    "$$\n",
    "\\mathcal{L}_n (w) = \\frac{1}{n} \\, \\sum_{i=1}^{n} \\, \\ell^{(i)} (y, \\hat{y})\n",
    "$$\n",
    "donde se define la pérdida como una pérdida cuadrática y se asume un modelo lineal para $\\hat{y}$:\n",
    "$$\n",
    "\\ell (y, \\hat{y}) = \\left\\| y - \\hat{y} \\right\\|^2 \\, , \n",
    "$$\n",
    "$$\n",
    "\\text{con} \\, \\, \\hat{y} = w^T x\\, ; \\, x,w \\in \\mathbb{R}^{p+1}\n",
    "$$\n",
    "\n",
    "En general, la pérdida es una función convexa y por lo tanto tiene un mínimo global. Para hallar el óptimo $w^{*}$ que minimice esta pérdida, se anula el gradiente y se resuelve el correspondiente sistema de ecuaciones.\n",
    "$$\n",
    "\\nabla_n \\mathcal{L}_n (w) = 0 \\, \\, \\Rightarrow \\, \\, w^{*} = (x^Tx)^{-1}x^Ty\n",
    "$$\n",
    "$$\n",
    "\\text{donde} \\, \\, w^{*} = \\text{argmin} \\mathcal{L}_n (w) \\, .\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.1. Métodos Iterativos\n",
    "Se quiere encontrar una estrategia que minimice la $ \\, \\mathcal{L}_n (w)$  iterativamente donde $ \\, w_{t+1} = w_t + h(w_t)$ .\n",
    "\n",
    "Si $h(w_t)$ como la dirección de máximo descenso, ¿cómo definimos esta dirección de descenso? Con el gradiente.Si se define previamente un tamaño o longitud de paso $\\eta$, entonces, nos acercaremos al mínimo de la función de manera iterativa de la siguiente forma:\n",
    "$$\n",
    "w_{t+1} = w_t - \\eta \\nabla_{n} \\mathcal{L}_n (w) \\, \\bigg\\rvert_{w=w_t}\n",
    "$$\n",
    "Lo anterior se puede representar gráficamente como en la figura 1. En este caso, se alcanza una buena aproximación del mínimo en $T$ pasos. Por lo que\n",
    "$$\n",
    "w_T = w^{*} \\, .\n",
    "$$\n",
    "\n",
    "![descenso-en-gradiente](https://i.imgur.com/HXHzXNz.png)\n",
    "\n",
    "Como se mencionó anteriormente, se debe definir un tamaño de paso. Aquí es donde hay que tener cuidado, pues si se escoge un tamaño de paso muy grande, podemos pasarnos del mínimo y quedarnos oscilando alrededor del mínimo sin llegar nunca a él. Por otra parte, si el tamaño de paso es muy corto, entonces el descenso podríamos requerir muchas iteraciones para llegar al mínimo y el proceso de descenso sería muy lento. Ambas situaciones son problemas de eficiencia y se ilustran en la figura 2.\n",
    "\n",
    "![descenso-en-gradiente](https://i.imgur.com/NlD8h0s.png)\n",
    "\n",
    "### Eficiencia computacional\n",
    "\n",
    "¿Qué pasaría con los cálculos anteriores si el número de observaciones $n$ fuera muy grande? ¿Afectaría el cómputo de $\\nabla_{n} \\mathcal{L}_n (w)$?\n",
    "\n",
    " Recordemos la forma de la función de pérdida:\n",
    " $$\n",
    " \\mathcal{L}_n (w) = \\frac{1}{n} \\, \\sum_{i=1}^{n} \\, \\ell^{(i)} (w) \\, ,\n",
    " $$\n",
    " \n",
    " Y la definición del gradiente:\n",
    " \n",
    " $$\n",
    " \\nabla_n = \\left [ \\begin{array}{cc}\n",
    "\\frac{\\partial}{\\partial w_0}\\\\\n",
    "\\frac{\\partial}{\\partial w_1}\\\\\n",
    "\\vdots\\\\\n",
    "\\frac{\\partial}{\\partial w_p}\n",
    "\\end{array}\n",
    "\\right ] \\in \\mathbb{R}^{p+1} \\, .\n",
    " $$\n",
    " \n",
    " Entonces, para calcular el gradiente de la función de pérdida se tendría que calcular el gradiente de $n$ términos individuales:\n",
    " \n",
    " $$\n",
    " \\nabla_n \\mathcal{L}_n (w) = \\nabla_n \\left( \\frac{1}{n} \\, \\sum_{i=1}^{n} \\, \\ell^{(i)} (w) \\right) =  \\frac{1}{n} \\, \\sum_{i=1}^{n} \\, \\nabla_n \\, \\ell^{(i)} (w) \\, .\n",
    " $$\n",
    " \n",
    " $$\\ell^{(i)} (y, \\hat{y}) = ||y^{(i)} - \\hat{y}^{(i)} || ^2 = ||y^{(i)} - w^T x^{(i)} || ^2 = \\ell^{(i)} (w)$$\n",
    " \n",
    " El cálculo resulta lento cuando se tienen millones o incluso varios miles de datos. ¿Cómo podemos aliviar el costo computacional? \n",
    " \n",
    " Una opción es utilizar el método de **descenso estocástico**. \n",
    " \n",
    " ### Descenso estocástico\n",
    " El descenso estocástico es una aproximación bien comportada al gradiente. En notación matemática:\n",
    " $$\n",
    " \\nabla_n  \\mathcal{L}_n (w) \\thickapprox \\tilde{\\nabla}_n \\mathcal{L}_n (w) \\, .\n",
    " $$\n",
    " \n",
    "En este método el gradiente se aproxima utilizando una única observación. Se tienen {1,2,...,n} puntos, se escoge uno al azar y se evalúa el gradiente en este punto. Esta será nuestra aproximación. Es decir,\n",
    "$$\n",
    "\\tilde{\\nabla}_n \\mathcal{L}_n (w) = \\nabla_n \\ell^{(k)} (w) \\, , \\, \\, \\text{donde } \\, k  \\sim U[1,n] \\, .\n",
    " $$\n",
    " \n",
    "Se espera que este estimador sea  insesgado y que\n",
    "$$\n",
    " \\mathbb{E}_{k  \\sim U[1,n]} \\left(  \\tilde{\\nabla}_n \\mathcal{L}_n (w) \\right) = \\nabla_n \\mathcal{L}_n (w)\n",
    "$$\n",
    "$$\n",
    "\\frac{1}{n} \\, \\sum_{i=1}^{n} \\, \\nabla_n \\, \\ell^{(k)} (w) = \\nabla_n \\mathcal{L}_n (w)\n",
    "$$\n",
    "$$\n",
    "\\text{con } \\tilde{\\nabla}_n^{SGD} \\mathcal{L}_n (w) = \\nabla_n \\, \\ell^{(k)} (w)\n",
    "$$\n",
    "\n",
    "A pesar de que aquí también utilizamos todas las observaciones, el costo computacional es menor pues los cálculos que se realizan son mucho más sencillas que en el descenso en gradiente.\n",
    "\n",
    "Sin embargo, este método también presenta algunos problemas:\n",
    "+ Dado que se utiliza muestreo aleatorio para seleccionar el punto a utilizar, podemos perder la contribución de algunas observaciones.\n",
    "+ Además, se pueden presentar problemas de eficiencia en los núcleos de la computadora en la que se realice el cálculo pues sólo se evalúan los puntos de uno en uno.\n",
    "\n",
    "¿Cómo solucionamos estos problemas?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.2. Descenso en gradiente estocástico por bloques\n",
    "Para este método asignamos el estimador:\n",
    "$$\n",
    "\\tilde{\\nabla}_n^{(B)} \\mathcal{L}_n (w) = \\frac{1}{|B|} \\sum_{i \\in B} \\nabla_n \\, \\ell^{(i)} (w)\n",
    "$$\n",
    "donde $B$ es un subconjunto de observaciones tal que $B \\subset \\{ 1,2,...,n \\}$ ,  $|B| < n$. Así, se obtienen un total de m bloques de tamaño $|B|$ tales que:\n",
    "\n",
    "$$\n",
    "m \\, |B| = n \\, \\, \\, \\Rightarrow \\, \\, \\, |B| = \\frac{n}{m}\n",
    "$$\n",
    "\n",
    "![romper-bloques](https://i.imgur.com/EY1ohOr.png)\n",
    "\n",
    "Por lo general, el número de bloques $m$ se decide teniendo en cuenta la cantidad de datos que se tienen y el número de núcleos de la computadora.\n",
    "\n",
    "En cada época o *epoch* del descenso se procesan los $m$ bloques de manera secuencial, para conseguir una actualización de lo parámetros y repetimos.\n",
    "\n",
    "Con este método es mucho menos probable caer en un punto silla cuando se busca el mínimo que con el descenso en gradiente clásico. De hecho, para el descenso por bloques !se tiene probabilidad 1 de escapar de un punto silla!\n",
    "\n",
    "Además, al pasar por todos los bloques en cada época, se garantiza que estamos tomando en cuenta las contribuciones de todas las observaciones para el cálculo de la dirección de descenso. Por lo que hacer el descenso estocástico por bloques es que logra reducir la varianza en comparación con el descenso estocástico clásico:\n",
    "$$\n",
    "\\mathbb{V} \\left( \\tilde{\\nabla}_n^{(B)} \\mathcal{L}_n (w) \\right) \\leq \\mathbb{V} \\left( \\tilde{\\nabla}_n^{SGD} \\mathcal{L}_n (w) \\right)\n",
    "$$\n",
    "\n",
    "![epoch](https://i.imgur.com/Y5td5uY.png)\n",
    "\n",
    "Para hacer predicciones entonces se aproxima $w^* \\thickapprox w_{\\tau}$ para obtener:\n",
    "$$\n",
    "y^{*} = w_{\\tau}^T x^{*}\n",
    "$$\n",
    "\n",
    "También como se ha comentado antes, la pérdida cuadrática se relaciona con la máxima verosimilitud (bajo un modelo de errores gaussianos). En este caso, el valor real es la aproximación obtenida más un error cuyo valor se desconoce. Así,\n",
    "\n",
    "$$\n",
    "y = \\hat{y} + \\epsilon\n",
    "$$\n",
    "\n",
    "$$\n",
    "\\text{donde } \\, \\, \\epsilon \\sim N(0, \\sigma^2)\n",
    "$$\n",
    "\n",
    "¿Cómo se relaciona el modelo lineal con una red neuronal?\n",
    "Para generar estas predicciones en este modelo simple se tienen dos capas: una capa de entrada con $p$ unidades (observaciones con sus componentes) que contribuyen a una capa de salida (predicción) con una sola unidad.\n",
    "\n",
    "A esto le llamamos una red densa pues se asume que cada uno de los nodos de la capa de entrada está conectada con la capa de salida, es decir, se tienen todas las conexiones posibles.\n",
    "![capas](https://i.imgur.com/2EJL5NN.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
