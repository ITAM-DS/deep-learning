{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Más modelos basados en convoluciones"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Introducción\n",
    "\n",
    "Estos modelos se refieren a que ya no estamos analizando la capa, sino bloques. En 2014, un grupo de investigadores diseñaron un modelo convolucional (GoogleNet), ganando así Imagenet. No se trata únicamente de construir un modelo, sino de mejorarlo. La idea es entender lo que se hace con los filtros, por qué no hay un filtro adecuado para un problema en particular. Entonces lo que ellos desarrollan es: \n",
    "\n",
    "- Bloques __Inception__ (ir a niveles más profundos para obtener más abstracciones útiles). \n",
    "\n",
    "#### Desarrollo\n",
    "\n",
    "Un grupo de investigadores de Google aplican filtros de convolución en paralelo, así que la idea es que al tener distintos filtros con distintas resoluciones se encargarán de obtener distintas características de la misma imagen con diferentes niveles de atención. Al final un bloque de __Inception__ se ve de la siguiente forma: \n",
    "\n",
    "<img src=\"bloques_inception.png\" alt=\"200\" width=\"400\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "donde 192x28x28 se refiere a la imagen que recibimos o recibimos la salida de una capa intermedia. Se le aplican cuatro bloques de filtros distintos cada uno con cierto objetivo, por ejemplo un bloque de un kernel de 1x1 (1x1 Conv (64)), cuando la imagen viene de 192 canales, busca reducir o mantener el cómputo estable, es decir, buscar una representación como si fuera una capa densa. También se agrega un bloque capaz de extraer información a un nivel donde se pueda resumir información espacial con una operación __Pooling__. Los kernels de 1x1 (1x1 Conv(96) y 1x1 Conv (16)) buscan, tanto reducir los canales como aumentar en paralelo la complejidad del modelo mismo. \n",
    "\n",
    "Algo interesante de estos modelos es que al aplicar distintos filtros con distintas resoluciones, obtenemos un modelo que no requiere tantos parámetros como lo hubiera requerido un modelo con un solo bloque convolucional. Por ejemplo, si se quisiera obtener, con un bloque de convoluciones usual, 256 canales con un filtro de 25 cuando estamos consumiendo una imagen de 28x28 en 192 canales, lo que se va a necesitar es alrededor de 1.22 millones de parámetros o si se usa un kernel de 3x3, es decir, 256x9x192, se necesitará alrededor de 0.44 millones de parámetros. Sin embargo, para contruir un bloque de __Inception__ de este estilo (256x9x192) tendrá alredor de 0.16 millones de parámetros.\n",
    "\n",
    "Lo interesante de esto, es que se están requiriendo pocos parámetros en estos bloques de __Inception__ y se están obteniendo resultados del estado del arte (módulo 2014) para ganar una competencia que antes se ganó con modelos más complejos, es decir, que tienen un número de parámetros alto. Sin embargo, la complejidad de estos modelos de bloques de __Inception__ esta basada en los bloques que lo componen no en el número de parámetros. \n",
    "\n",
    "Al final el modelo de __Inception__ queda de la siguiente manera:\n",
    "\n",
    "<img src=\"modelo_inception.png\" alt=\"100\" width=\"200\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lo que significa que se trata de una construcción por bloques."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
