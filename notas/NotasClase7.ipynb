{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "NotasClase7.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "UFF_DLToYctH"
      },
      "source": [
        "#**Clase 7: Regularización**"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Sn69Ing1Y5DH"
      },
      "source": [
        "<p align = \"justify\">Cuando incorporamos modelos de aprendizaje muy flexibles, como lo son los <b>modelos multicapa</b>, tenemos una familia de funciones muy flexibles capaz de predecir y de ajustarse a casi cualquier cosa con un número suficiente de datos. <b>El problema es que son tan flexibles que podemos caer en el riesgo de sobreajustar los datos observados</b>. Si un modelo sobreajusta los datos de entrenamiento tendría un mal desempeño en datos que no haya visto antes aunque provengan de la misma población. </p>\n",
        "\n",
        "\\\n",
        "\n",
        "Definimos **sobreajustar** como la capacidad que tiene un modelo para entender una particularidad de los datos de entrenamiento como principio general de la población de la que viene.\n",
        "\n",
        "\n",
        "La flexibilidad de un modelo está relacionada con su capacidad/complejidad del modelo:\n",
        "\n",
        "*   Número de parámetros \n",
        "*   Número de datos de entrenamiento\n",
        "*   Restricciones en los parámetros\n",
        "\n",
        "Hacer las transformaciones no aumenta la complejidad pero si puede afectar el periodo de entrenamiento.\n",
        "\n",
        "\\\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4Hwk4ROTYoTJ"
      },
      "source": [
        "<p align = \"justify\">Dos opciones para mitigar el riesgo de sobreajuste son la <b>regularización</b> y la <b>recolección de más datos</b>. La regularización es una forma eficiente y la recolección de más datos es una forma eficaz de asegurarnos que nuestro modelo no está aprendiendo particularidades. Se dice eficiente porque en la práctica puede que no sea factible obtener nuevos datos. Sea por cuestiones de costos, tiempo o porque estamos limitados a un número particular de observaciones. Un ejemplo, son las limitantes para la adquisición de nuevas imágenes satelitales. </p>\n",
        "\n",
        "\n",
        "* Regularización       $\\to$ eficiente \n",
        "* Recolección de más datos $\\to$ eficaz\n",
        "\n",
        "\n",
        "\\\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Pd8YuPFX13Db"
      },
      "source": [
        "\\\n",
        "\n",
        "\n",
        "##**Regularización** \n",
        "\n",
        "Se puede combinar el ajuste con algún tipo de restricción para mitigar el riesgo de sobreajuste. \n",
        "\n",
        "\n",
        "\n",
        "\n",
        " $$ L(\\alpha) =  \\frac{1}{n} \\sum \\limits _{i=1} ^{n} (y - \\hat{y}(\\alpha) )^2 $$\n",
        "\n",
        " $$\\hat{\\alpha} = \\textrm{arg min}\\; L(\\alpha) + ||\\alpha||^2$$\n",
        "\n",
        "\n",
        "\n",
        " $$  \\textrm{Siendo} \\: ||\\alpha||\u001b\u001b^2 \\: \\textrm{la penalización} $$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZOwT95M7XlMt"
      },
      "source": [
        "Lo que de alguna queremos es controlar el tamaño del vector $\\alpha$, de tal forma que no permitamos que $\\alpha$ como vector sea muy grande. \n",
        "\n",
        "###**1.Optimización con restricciones**\n",
        "\n",
        "Lo que usualmente se hacia en un principio, se definia como un problema de optimización con restricciones.\n",
        "\n",
        "$$min. L(\\alpha)$$\n",
        "$$s.a. ||\\alpha||^2 < \\theta$$\n",
        "\n",
        "$\\theta$ controla la complejidad. Nos ayuda a controlar el espacio de búsqueda.\n",
        "\n",
        "$$ \\alpha^*_{R} = \\textrm{arg min } L(\\alpha)$$\n",
        "$$s.a. ||\\alpha||^2 < \\theta$$\n",
        "\n",
        "\n",
        "Restricción fuerte en el sentido de que no le permitimos a $\\alpha$ excederse de cierta zona. \n",
        "\n",
        "También esta sujeta a escoger de manera adecuada este parámetro. \n",
        "Para esto, lo más fácil es utilizar **el método de Lagrange** para definir una función más simple para minimizar. \n",
        "\n",
        "$$min\\, L(\\alpha)+ \\frac{\\lambda}{2}||\\alpha||^2$$\n",
        "\n",
        "Donde $\\lambda$ controla el grado de penalización:\n",
        "\n",
        "  * $\\lambda = 0 \\implies$ no hay restricciones\n",
        "  * $\\lambda = 0 \\implies \\alpha^* \\to \\infty$\n",
        "\n",
        "$||\\alpha||_2 = \\sum \\limits _{i=1} ^{p} d_{i}^2$\n",
        "\n",
        "\n",
        "$||\\alpha||_1 = \\sum \\limits _{i=1} ^{p} |d_{i}|$\n",
        "\n",
        "$\\alpha_0$ no esta sujeto a penalización\n",
        "\n",
        "En la práctica se ha visto que penalizar o no penalizar el intercepto o el coeficiente del sesgo no tiene ninguna repercusión práctica. \n",
        "\n",
        "Esta función se minimiza en donde ambas funciones (pérdida y norma) sean tangentes. \n",
        "\n",
        "El tamaño del vector $\\alpha$ se distribuye entre sus componentes. \n",
        "Se conoce Ridge limitante de la norma dos. \n",
        "\n",
        "La tangencia en una esquina implica que el tamaño o concentración del vector solo son:\n",
        "\n",
        "* La solución está en las esquinas. Lo que implica que hay algunos coeficientes que son iguales a cero. \n",
        "* La solución es rala (*sparse*), por lo que esta misma norma actua como mecanismo de selección de variables. \n",
        "* Lasso\n",
        "\n",
        "\n",
        "Escoger una norma sobre otra representa lo que queriamos que tenga nuestra solución: por un lado si queremos que nuestra solución tenga tamaño mínimo, va a ser el tamaño más pequeño posible aunque todos los componentes estén activos buscamos utilizar la norma dos. En cambio, si quisieramos utilizar o recuperar una solución donde se haga una selección automática de variables podemos utilizar la norma uno. Varios componentes se van asignar a cero. \n",
        "\n",
        "Aqui nos importa la diferenciabilidad de estas funciones de penalización.\n",
        "Hay métodos eficientes y bien estudiados para resolver estos problemas. \n",
        "\n",
        "* Weight decay : regularización con norma dos\n",
        "\n",
        "Si quisieramos resolver este problema de minimización con restricciones \n",
        "\n",
        "$$min\\, L(\\alpha)+ \\frac{\\lambda}{2}||\\alpha||^2$$\n",
        "\n",
        "\n",
        "$$\\nabla_w (L(w,b)+ \\frac{\\lambda}{2}||w||^2 = \\nabla_w L(w,b)+\\lambda w$$\n",
        "\n",
        "El gradiente de la suma es la suma de los gradientes\n",
        "$w^{(t+1)} = w^(t) - \\eta \\bar{V} w\\, \\mathcal{L}_R (w,b)$\n",
        "$= (1-\\lambda\\eta)w^(t)-\\eta\\nabla_w \\mathcal{L}_R | _{w=w^{(t)}} $ \n",
        "\n",
        "Donde $\\eta$ es la longitud del paso\n",
        "Expresamos $\\lambda \\eta < 1$\n",
        "\n",
        "$\\lambda \\eta < 1$ \\to reducir el vector $w^{t}$\n",
        "\n",
        "El gradiente de la suma es la suma de los gradientes\n",
        "\n",
        "\n",
        "estado\n",
        "\n",
        "dirección del gradiente usual que consideramos\n",
        "\n",
        "Pasos suficientemente cortos y que nuestra penalización en los coeficientes no sea tan grande. Estamos permitiendonos mover libres sin tanta complejidad.\n",
        "Dado esto las actualizaciones reducen el vector $\\alpha$.\n",
        "\n",
        "Efecto multiplicativo que esta reduciendo el tamaño del vector\n",
        "\n",
        "¿Cómo se escoge $\\lambda$? Por técnicas de validación cruzada.\n",
        "\n",
        "El objetivo de la regularización norma es minimizar la función de pérdida, incorporando una noción de que nuestra solución tiene que estar restringida en tamaño.\n",
        "\n",
        "También restringe el tamaño de este vector $\\frac{\\lambda}{2}||\\alpha||^2$\n",
        "\n",
        "\n",
        "En el contexto de regresón polinomial una solución con norma pequeña \n",
        "\n",
        "$||\\alpha||^2<<1 \\implies$ penalizando no permitimos que los términos de grado muy alto tengan tanta importancia\n",
        "\n",
        "Lo que quisieramos hacer con esto, o lo que hace en la práctica esta penalización es que al menos que realmente el modelo necesite un término de grado muy elevado, lo va a incorporar en la solución.\n",
        "\n",
        "Mientras no sea tan importante o no se requiera para el procedimiento de penalización, le va a dar un peso muy bajo, si estamos usando norma dos y lo va a mantener hasta cierto nivel de tolerancia. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YGA5KU3dGDFW"
      },
      "source": [
        "$\\mathcal{L}$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lC2o-pTsZzFL"
      },
      "source": [
        "2.- Dropout\n",
        "\n",
        "Otra técnica de regularización. En un modelo multicapa queremos que la arquitectura de la red sea robusta respecto a las conexiones que tiene.\n",
        "\n",
        "Es decir, la idea de hacer un modelo que no dependa de que tiene todas conexiones todo el tiempo. \n",
        "\n",
        "Conexiones no densas.\n",
        "\n",
        "Idea: durante el entrenamiento eliminar ciertas conexiones es eliminar un nodo o incluso dos. \n",
        "\n",
        "Las señales que estamos recibiendo en la capa de entradas quisieramos que fluyan hasta la capa de salida de manera robusta, sin tener que utilizar todas las conexiones con un procedimiento aleatorio que puede apagar ciertas unidades en cualquier momento. \n",
        "\n",
        "Una red o una transmisión de información en esta estructura que sea robusta lo podria hacer si tiene este entendimiento durante el entrenamiento, dependiendo que posiblemente haya unidades que estén apagadas o prendidas en cualquier momento del procedimiento. \n",
        "\n",
        "Lo que hace el método de dropout es cambiar durante el entrenamiento, asignar las unidades de salida como un evento Bernoulli, donde la unidad \"escupe\" una señal igual a cero. \n",
        "\n",
        "\n",
        "¿Qué es lo que hace esto? Pensemoslo como una variable aleatoria. \n",
        "\n",
        "La salida de cada unidad oculta es precisamente la que tendriamos si esa variable aleatoria no se hubiera apagado.\n",
        "\n",
        "Lo importante de esta técnica, es que solo se aplica duranre el enrenamiento. \n",
        "\n",
        "Cuando estamos calculando los gradientes y estamos efectuando este proceso iterativo de optimización, apagamos y prendemos unidades con cierta probabilidad.\n",
        "\n",
        "La ventaja de la arquitectura es que podriamos aplicar probabilidades distintas si tuvieramos más capas. Usualmente asignamos una probabilidad más alta de falla conforme más cercanos estemos a la capa de entrada y una probabilidad menor conforme más cercanos estemos a la capa de salida. \n",
        "\n",
        "Tambien tiene ciertas garantias técnicas que con mucho cuidado se pudieran interpretar como un procedimiento de regularización. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8mvCQ4m7Y9LE"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYNUW2epHiGA"
      },
      "source": [
        "  \n",
        "\n",
        "$\n",
        "    h^´= \n",
        "\\begin{cases}\n",
        "    0 & \\text{con probabilidad p} \\\\\n",
        "    \\frac{h}{1-p}& \\text{e.o.c} \\\\\n",
        "\\end{cases}\n",
        "$"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SPRpxi1NGmLL"
      },
      "source": [
        "¿Qué es lo que hace esto? Pensémoslo como una variable aleatoria\n",
        "\n",
        "$E(h^´)= o *p + \\frac{h}{1-p}(1-p)$ \\\\\n",
        "$E(h^´)=h$\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9dEhuu7wbuJ_"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}